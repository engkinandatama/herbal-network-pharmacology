{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MD Analysis - 264THM + PPARG (50 ns Full Trajectory)\n",
                "\n",
                "**Purpose:** Re-analyze the complete 50 ns trajectory by concatenating all checkpoint files\n",
                "\n",
                "**Input:** Output from completed MD simulation notebook\n",
                "\n",
                "**Accelerator:** CPU is sufficient (no GPU needed for analysis)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Install GROMACS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "set -e\n",
                "apt-get update -qq\n",
                "apt-get install -qq -y gromacs\n",
                "gmx --version | head -3\n",
                "echo 'GROMACS: OK'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Setup Paths and Copy Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "\n",
                "CONFIG = {\n",
                "    'complex_name': '264THM_PPARG',\n",
                "    'total_time_ns': 50,\n",
                "    'checkpoint_interval_ns': 10,\n",
                "}\n",
                "\n",
                "# Input dataset from completed MD simulation\n",
                "INPUT_DIR = Path('/kaggle/input/264thm-pparg-md-analysis')\n",
                "WORK_DIR = Path(f\"/kaggle/working/{CONFIG['complex_name']}\")\n",
                "ANALYSIS_DIR = WORK_DIR / 'analysis_full'\n",
                "\n",
                "ANALYSIS_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(f'Input: {INPUT_DIR}')\n",
                "print(f'Output: {ANALYSIS_DIR}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check available files in input dataset\n",
                "if INPUT_DIR.exists():\n",
                "    for item in sorted(INPUT_DIR.iterdir()):\n",
                "        if item.is_dir():\n",
                "            print(f'\ud83d\udcc1 {item.name}/')\n",
                "            for sub in sorted(item.iterdir())[:5]:\n",
                "                print(f'   - {sub.name}')\n",
                "            if len(list(item.iterdir())) > 5:\n",
                "                print(f'   ... and more')\n",
                "        else:\n",
                "            print(f'\ud83d\udcc4 {item.name}')\n",
                "else:\n",
                "    print('ERROR: Input dataset not found!')\n",
                "    print('Please add the output from the MD simulation as a dataset.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\\n",
                "# Unzip checkpoints if uploaded as zip\\n",
                "cd /kaggle/input/264thm-pparg-md-analysis\\n",
                "if [ -f checkpoints.zip ]; then\\n",
                "    echo 'Extracting checkpoints.zip...'\\n",
                "    unzip -q checkpoints.zip -d /kaggle/working/\\n",
                "    echo 'Done!'\\n",
                "    ls -la /kaggle/working/checkpoints/\\n",
                "else\\n",
                "    echo 'No zip file, using direct folders'\\n",
                "fi"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Concatenate All Trajectory Files\n",
                "\n",
                "Merge all checkpoint `.xtc` files into one complete 50 ns trajectory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find all XTC files from checkpoints\\n",
                "checkpoint_xtcs = []\\n",
                "\\n",
                "# Check extracted checkpoints first\\n",
                "extracted_dir = Path('/kaggle/working/checkpoints')\\n",
                "if extracted_dir.exists():\\n",
                "    print('Using extracted checkpoints from zip')\\n",
                "    base_dir = extracted_dir\\n",
                "else:\\n",
                "    base_dir = INPUT_DIR\\n",
                "\\n",
                "for ns in range(CONFIG['checkpoint_interval_ns'], CONFIG['total_time_ns'] + 1, CONFIG['checkpoint_interval_ns']):\\n",
                "    # Try multiple path patterns\\n",
                "    patterns = [\\n",
                "        base_dir / f'checkpoint_{ns}ns/md.xtc',\\n",
                "        INPUT_DIR / f'checkpoints/checkpoint_{ns}ns/md.xtc',\\n",
                "        INPUT_DIR / f'{CONFIG[\"complex_name\"]}/checkpoints/checkpoint_{ns}ns/md.xtc',\\n",
                "    ]\\n",
                "    found = False\\n",
                "    for xtc_path in patterns:\\n",
                "        if xtc_path.exists():\\n",
                "            checkpoint_xtcs.append(str(xtc_path))\\n",
                "            print(f'\u2705 Found: {xtc_path.name} at {xtc_path.parent}')\\n",
                "            found = True\\n",
                "            break\\n",
                "    if not found:\\n",
                "        print(f'\u274c Missing: checkpoint_{ns}ns')\\n",
                "\\n",
                "print(f'\\\\nTotal XTC files found: {len(checkpoint_xtcs)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Also check for the main md/ folder trajectory\n",
                "main_xtc = INPUT_DIR / f\"{CONFIG['complex_name']}/md/md.xtc\"\n",
                "if main_xtc.exists():\n",
                "    print(f'\u2705 Main trajectory found: {main_xtc}')\n",
                "    main_xtc_size = main_xtc.stat().st_size / 1e6\n",
                "    print(f'   Size: {main_xtc_size:.1f} MB')\n",
                "else:\n",
                "    print('Main md/md.xtc not found, will use checkpoint files')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find all XTC files from checkpoints\\n",
                "checkpoint_xtcs = []\\n",
                "\\n",
                "# Check extracted checkpoints first\\n",
                "extracted_dir = Path('/kaggle/working/checkpoints')\\n",
                "if extracted_dir.exists():\\n",
                "    print('Using extracted checkpoints from zip')\\n",
                "    base_dir = extracted_dir\\n",
                "else:\\n",
                "    base_dir = INPUT_DIR\\n",
                "\\n",
                "for ns in range(CONFIG['checkpoint_interval_ns'], CONFIG['total_time_ns'] + 1, CONFIG['checkpoint_interval_ns']):\\n",
                "    # Try multiple path patterns\\n",
                "    patterns = [\\n",
                "        base_dir / f'checkpoint_{ns}ns/md.xtc',\\n",
                "        INPUT_DIR / f'checkpoints/checkpoint_{ns}ns/md.xtc',\\n",
                "        INPUT_DIR / f'{CONFIG[\"complex_name\"]}/checkpoints/checkpoint_{ns}ns/md.xtc',\\n",
                "    ]\\n",
                "    found = False\\n",
                "    for xtc_path in patterns:\\n",
                "        if xtc_path.exists():\\n",
                "            checkpoint_xtcs.append(str(xtc_path))\\n",
                "            print(f'\u2705 Found: {xtc_path.name} at {xtc_path.parent}')\\n",
                "            found = True\\n",
                "            break\\n",
                "    if not found:\\n",
                "        print(f'\u274c Missing: checkpoint_{ns}ns')\\n",
                "\\n",
                "print(f'\\\\nTotal XTC files found: {len(checkpoint_xtcs)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "set -e\n",
                "cd /kaggle/working\n",
                "\n",
                "echo \"=== Concatenating trajectories ===\"\n",
                "\n",
                "# Get XTC files\n",
                "XTC_FILES=$(cat xtc_files.txt | tr '\\n' ' ')\n",
                "echo \"Files: $XTC_FILES\"\n",
                "\n",
                "# Concatenate all XTC files into one\n",
                "if [ -n \"$XTC_FILES\" ]; then\n",
                "    gmx trjcat -f $XTC_FILES -o 264THM_PPARG/analysis_full/full_trajectory.xtc -cat\n",
                "    echo \"\"\n",
                "    echo \"=== Full trajectory created ===\"\n",
                "    ls -lh 264THM_PPARG/analysis_full/full_trajectory.xtc\n",
                "else\n",
                "    echo \"ERROR: No XTC files found!\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copy TPR file for analysis\n",
                "tpr_source = list(INPUT_DIR.rglob('md.tpr'))\n",
                "if tpr_source:\n",
                "    shutil.copy(tpr_source[0], ANALYSIS_DIR / 'md.tpr')\n",
                "    print(f'\u2705 Copied TPR from: {tpr_source[0]}')\n",
                "else:\n",
                "    print('\u274c TPR file not found!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Run Full 50 ns Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "set -e\n",
                "cd /kaggle/working/264THM_PPARG/analysis_full\n",
                "\n",
                "echo \"=== Checking trajectory info ===\"\n",
                "gmx check -f full_trajectory.xtc 2>&1 | tail -20"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "set -e\n",
                "cd /kaggle/working/264THM_PPARG/analysis_full\n",
                "\n",
                "echo \"=== RMSD Analysis (Backbone) ===\"\n",
                "# Group 4 = Backbone\n",
                "printf '4\\n4\\n' | gmx rms -s md.tpr -f full_trajectory.xtc -o rmsd_backbone_50ns.xvg -tu ns\n",
                "\n",
                "echo \"\"\n",
                "echo \"=== RMSF Analysis ===\"\n",
                "printf '4\\n' | gmx rmsf -s md.tpr -f full_trajectory.xtc -o rmsf_50ns.xvg -res\n",
                "\n",
                "echo \"\"\n",
                "echo \"=== Radius of Gyration ===\"\n",
                "printf '1\\n' | gmx gyrate -s md.tpr -f full_trajectory.xtc -o gyrate_50ns.xvg\n",
                "\n",
                "echo \"\"\n",
                "echo \"=== Analysis Complete ===\"\n",
                "ls -la *.xvg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Generate Plots"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "def parse_xvg(filename):\n",
                "    \"\"\"Parse GROMACS XVG file\"\"\"\n",
                "    data = []\n",
                "    with open(filename, 'r') as f:\n",
                "        for line in f:\n",
                "            if not line.startswith(('#', '@')):\n",
                "                values = [float(x) for x in line.split()]\n",
                "                if values:\n",
                "                    data.append(values)\n",
                "    return np.array(data)\n",
                "\n",
                "# Create figure\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "fig.suptitle(f\"{CONFIG['complex_name']} - MD Analysis (FULL 50 ns)\", fontsize=14, fontweight='bold')\n",
                "\n",
                "# RMSD\n",
                "rmsd = parse_xvg(str(ANALYSIS_DIR / 'rmsd_backbone_50ns.xvg'))\n",
                "axes[0].plot(rmsd[:, 0], rmsd[:, 1], color='#2E86AB', linewidth=0.8)\n",
                "axes[0].set_xlabel('Time (ns)')\n",
                "axes[0].set_ylabel('RMSD (nm)')\n",
                "axes[0].set_title('Backbone RMSD')\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "axes[0].set_xlim(0, 50)\n",
                "\n",
                "# RMSF\n",
                "rmsf = parse_xvg(str(ANALYSIS_DIR / 'rmsf_50ns.xvg'))\n",
                "axes[1].plot(rmsf[:, 0], rmsf[:, 1], color='#2E86AB', linewidth=0.8)\n",
                "axes[1].set_xlabel('Residue')\n",
                "axes[1].set_ylabel('RMSF (nm)')\n",
                "axes[1].set_title('RMSF per Residue')\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "# Radius of Gyration\n",
                "gyrate = parse_xvg(str(ANALYSIS_DIR / 'gyrate_50ns.xvg'))\n",
                "axes[2].plot(gyrate[:, 0]/1000, gyrate[:, 1], color='#F18F01', linewidth=0.8)\n",
                "axes[2].set_xlabel('Time (ns)')\n",
                "axes[2].set_ylabel('Rg (nm)')\n",
                "axes[2].set_title('Radius of Gyration')\n",
                "axes[2].grid(True, alpha=0.3)\n",
                "axes[2].set_xlim(0, 50)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(str(ANALYSIS_DIR / f'{CONFIG[\"complex_name\"]}_analysis_50ns.png'), dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print('\\n=== Plot saved ===')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate statistics\n",
                "print('='*60)\n",
                "print('STATISTICS - Full 50 ns Simulation')\n",
                "print('='*60)\n",
                "\n",
                "# Overall stats\n",
                "print(f'\\nTime range: 0 - {rmsd[-1, 0]:.1f} ns')\n",
                "print(f'Total frames: {len(rmsd)}')\n",
                "\n",
                "# RMSD stats\n",
                "print(f'\\n--- RMSD (Backbone) ---')\n",
                "print(f'Average: {rmsd[:, 1].mean():.3f} \u00b1 {rmsd[:, 1].std():.3f} nm')\n",
                "print(f'Min: {rmsd[:, 1].min():.3f} nm')\n",
                "print(f'Max: {rmsd[:, 1].max():.3f} nm')\n",
                "\n",
                "# Equilibration check (last 20 ns)\n",
                "last_20ns = rmsd[rmsd[:, 0] >= 30]\n",
                "if len(last_20ns) > 0:\n",
                "    print(f'\\n--- RMSD (Last 20 ns, equilibrated) ---')\n",
                "    print(f'Average: {last_20ns[:, 1].mean():.3f} \u00b1 {last_20ns[:, 1].std():.3f} nm')\n",
                "\n",
                "# Rg stats\n",
                "print(f'\\n--- Radius of Gyration ---')\n",
                "print(f'Average: {gyrate[:, 1].mean():.3f} \u00b1 {gyrate[:, 1].std():.3f} nm')\n",
                "\n",
                "# RMSF - find flexible residues\n",
                "print(f'\\n--- RMSF Hotspots (Top 10 flexible residues) ---')\n",
                "rmsf_sorted = np.argsort(rmsf[:, 1])[::-1][:10]\n",
                "for idx in rmsf_sorted:\n",
                "    print(f'Residue {int(rmsf[idx, 0])}: {rmsf[idx, 1]:.3f} nm')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Additional Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "cd /kaggle/working/264THM_PPARG/analysis_full\n",
                "\n",
                "echo \"=== Hydrogen Bonds Analysis ===\"\n",
                "# Protein-Protein H-bonds\n",
                "printf '1\\n1\\n' | gmx hbond -s md.tpr -f full_trajectory.xtc -num hbnum_protein.xvg 2>/dev/null || echo \"H-bond analysis skipped\"\n",
                "\n",
                "echo \"\\n=== Secondary Structure (DSSP-like) ===\"\n",
                "# This may not work without DSSP, just attempt\n",
                "printf '1\\n' | gmx do_dssp -s md.tpr -f full_trajectory.xtc -o ss.xpm 2>/dev/null || echo \"DSSP not available, skipped\"\n",
                "\n",
                "echo \"\\n=== Available analysis files ===\"\n",
                "ls -la *.xvg *.png 2>/dev/null || echo \"No files yet\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot H-bonds if available\n",
                "hbond_file = ANALYSIS_DIR / 'hbnum_protein.xvg'\n",
                "if hbond_file.exists():\n",
                "    hbonds = parse_xvg(str(hbond_file))\n",
                "    \n",
                "    plt.figure(figsize=(10, 4))\n",
                "    plt.plot(hbonds[:, 0]/1000, hbonds[:, 1], color='#28A745', linewidth=0.5, alpha=0.7)\n",
                "    \n",
                "    # Running average\n",
                "    window = min(100, len(hbonds)//10)\n",
                "    if window > 1:\n",
                "        running_avg = np.convolve(hbonds[:, 1], np.ones(window)/window, mode='valid')\n",
                "        time_avg = hbonds[window//2:len(running_avg)+window//2, 0]/1000\n",
                "        plt.plot(time_avg, running_avg, color='#155724', linewidth=2, label='Running avg')\n",
                "    \n",
                "    plt.xlabel('Time (ns)')\n",
                "    plt.ylabel('Number of H-bonds')\n",
                "    plt.title(f'{CONFIG[\"complex_name\"]} - Protein H-bonds (50 ns)')\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    plt.xlim(0, 50)\n",
                "    plt.legend()\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(str(ANALYSIS_DIR / 'hbonds_50ns.png'), dpi=300)\n",
                "    plt.show()\n",
                "    \n",
                "    print(f'Average H-bonds: {hbonds[:, 1].mean():.1f} \u00b1 {hbonds[:, 1].std():.1f}')\n",
                "else:\n",
                "    print('H-bond analysis file not found')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copy all analysis files to output\n",
                "OUTPUT_DIR = Path('/kaggle/working/output')\n",
                "OUTPUT_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "# Copy analysis directory\n",
                "shutil.copytree(ANALYSIS_DIR, OUTPUT_DIR / f'{CONFIG[\"complex_name\"]}_analysis_50ns', dirs_exist_ok=True)\n",
                "\n",
                "print('=== Output Files ===')\n",
                "for f in sorted(OUTPUT_DIR.rglob('*')):\n",
                "    if f.is_file():\n",
                "        size_kb = f.stat().st_size / 1024\n",
                "        print(f'{f.relative_to(OUTPUT_DIR)}: {size_kb:.1f} KB')\n",
                "\n",
                "print('\\n=== FULL 50 NS ANALYSIS COMPLETE ===')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}